# NeDS 模型架构详解：特征融合与扩散过程

## 一、整体流程图

```
╔═══════════════════════════════════════════════════════════════════════════════╗
║                          NeDS 完整推理流程图                                   ║
╚═══════════════════════════════════════════════════════════════════════════════╝

┌─────────────────────────────────────────────────────────────────────────────┐
│                            1. 输入层 (Input Layer)                           │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  ┌─────────────────┐  ┌─────────────────┐  ┌────────────────┐              │
│  │ 当前噪声潜变量   │  │ 前帧图像特征    │  │ 变化掩码 + 文本提示 │             │
│  │ sample          │  │ pre_latents     │  │ controlnet_cond    │             │
│  │ (B, 4, H, W)    │  │ (B, 4, H, W)    │  │ post_mask: (B, 5, H, W)  │      │
│  └────────┬────────┘  └────────┬────────┘  └────────┬───────┘              │
│           │                    │                    │                      │
│           │                    └────────────────────┴────────────┬──────────┤
│           │                                                     │          │
│           │                    ┌──────────────────────────────┐ │          │
│           │                    │  timestep, event_label       │ │          │
│           │                    │  encoder_hidden_states       │ │          │
│           │                    └──────────────────────────────┘ │          │
│           │                                                     │          │
└─────────────────────────────────────────────────────────────────────────────┘
           │
           ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                      2. 时间与事件嵌入层 (Embedding Layer)                    │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  timestep → time_proj(Timesteps) → time_embedding(TimestepEmbedding)       │
│                                             │                               │
│                                             ▼                               │
│                              emb (B, 1280) [时间嵌入]                        │
│                                             │                               │
│                           ┌─────────────────┴─────────────────┐              │
│                           │                                   │              │
│                    [⭐ 关键改动点 ⭐]                           │              │
│                    event_embedding(7 → 1280)                 │              │
│                    将7种变化事件类型转换为向量                 │              │
│                           │                                   │              │
│                           ▼                                   ▼              │
│                event_emb(B, 1280)                    emb ← emb + event_emb  │
│                                                      最终时间嵌入 (B, 1280)   │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
           │
           ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                   3. 特征融合层 (Feature Fusion - Pre-conditioning)          │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  INPUT:  sample (B, 4, H, W)                                               │
│          pre_latents (B, 4, H, W)                                           │
│          controlnet_cond (B, 6, H, W) = [5通道掩码 + 1通道其他]            │
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────┐        │
│  │  步骤 1: 当前噪声编码                                            │        │
│  │  ────────────────────                                           │        │
│  │  sample ──→ conv_in(3×3 Conv) ──→ feature_in (B, 320, H, W)   │        │
│  │             (4 → 320 通道)                                      │        │
│  └─────────────────────────────────────────────────────────────────┘        │
│                                  │                                         │
│                                  ▼                                         │
│  ┌─────────────────────────────────────────────────────────────────┐        │
│  │  步骤 2: 前帧图像编码 (Image Conditioning)                       │        │
│  │  ────────────────────────────                                  │        │
│  │  pre_latents ──→ conv_latent(3×3 Conv)                         │        │
│  │                 (4 → 320 通道)                                  │        │
│  │                 ──→ image_cond (B, 320, H, W)                  │        │
│  │                                                                 │        │
│  │  [⭐ NeDS 创新点：直接使用前帧潜变量作为空间特征 ⭐]                │        │
│  └─────────────────────────────────────────────────────────────────┘        │
│                                  │                                         │
│                                  ▼                                         │
│  ┌─────────────────────────────────────────────────────────────────┐        │
│  │  步骤 3: 掩码编码 (Mask Conditioning)                            │        │
│  │  ──────────────                                                │        │
│  │  pmask (B, 5, H, W) ──→ pmask_embedding                        │        │
│  │                         ├─→ conv_in(3×3, 5→16)                │        │
│  │                         ├─→ layers[0-7]                       │        │
│  │                         │   (多层卷积 16→32→96→128)           │        │
│  │                         └─→ conv_out (zero_module)             │        │
│  │                         ──→ pmask_cond (B, 320, H, W)          │        │
│  │                                                                 │        │
│  │  [变化区域 5 通道解释]                                           │        │
│  │  • 通道 0-3: 变化置信度分数                                    │        │
│  │  • 通道 4: 不变/变化掩码                                       │        │
│  └─────────────────────────────────────────────────────────────────┘        │
│                                  │                                         │
│                                  ▼                                         │
│  ┌─────────────────────────────────────────────────────────────────┐        │
│  │  步骤 4: 特征融合 (Feature Concatenation & Fusion)               │        │
│  │  ──────────────────                                            │        │
│  │  concat([pmask_cond, image_cond], dim=1)                       │        │
│  │  ──→ fused_features (B, 640, H, W)                             │        │
│  │                                                                 │        │
│  │  [特征组合方式]                                                │        │
│  │  ┌─ 640 通道 ─┐                                                 │        │
│  │  ├─ 320 通道 ─ pmask_cond (掩码特征)                           │        │
│  │  ├─ 320 通道 ─ image_cond (前帧特征)                           │        │
│  │  └─────────────┘                                               │        │
│  └─────────────────────────────────────────────────────────────────┘        │
│                                  │                                         │
│                                  ▼                                         │
│  ┌─────────────────────────────────────────────────────────────────┐        │
│  │  步骤 5: 条件融合处理 (Fusion Processing)                        │        │
│  │  ───────────────────                                           │        │
│  │  fused_features (B, 640, H, W)                                 │        │
│  │         │                                                      │        │
│  │         ├─→ Conv2d(640 → 320, 1×1 kernel)                     │        │
│  │         ├─→ SiLU()                                            │        │
│  │         ├─→ Conv2d(320 → 320, 3×3 kernel)                     │        │
│  │         ├─→ SiLU()                                            │        │
│  │         └─→ Conv2d(320 → 320, 3×3 kernel)                     │        │
│  │         ──→ controlnet_cond_fused (B, 320, H, W)              │        │
│  │                                                                 │        │
│  │  [处理流程说明]                                                │        │
│  │  • 1×1 卷积: 特征降维 & 融合 (640 → 320)                       │        │
│  │  • SiLU 激活: 非线性变换增强特征表达                           │        │
│  │  • 两层 3×3 卷积: 捕捉空间相关性                               │        │
│  └─────────────────────────────────────────────────────────────────┘        │
│                                  │                                         │
│                                  ▼                                         │
│  ┌─────────────────────────────────────────────────────────────────┐        │
│  │  步骤 6: 特征相加 (Feature Addition)                            │        │
│  │  ───────────────                                               │        │
│  │  feature_in (B, 320, H, W)                                     │        │
│  │       +  controlnet_cond_fused (B, 320, H, W)                 │        │
│  │       ───────────────────────────────────────                 │        │
│  │  ──→  sample (B, 320, H, W)                                    │        │
│  │                                                                 │        │
│  │  [融合后结果]                                                  │        │
│  │  融合后的样本包含：                                            │        │
│  │  ✓ 当前噪声信息                                               │        │
│  │  ✓ 前帧空间特征                                               │        │
│  │  ✓ 变化区域掩码信息                                           │        │
│  │  ✓ 事件类型引导信息                                           │        │
│  └─────────────────────────────────────────────────────────────────┘        │
│                                  │                                         │
│                  OUTPUT: sample (B, 320, H, W)                              │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
           │
           ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│              4. UNet 下采样编码器 (UNet Encoder - Downsampling)              │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  sample (B, 320, H, W) + emb (B, 1280) + encoder_hidden_states             │
│                                                                              │
│  ┌─────────────────────────────────────────────────────────────────┐        │
│  │  Down Block 0 (CrossAttnDownBlock2D)                           │        │
│  │  ─────────────────────────────────────                         │        │
│  │  Input: sample (B, 320, H, W)                                  │        │
│  │  ├─→ ResNet + Self-Attn + Cross-Attn                          │        │
│  │  └─→ Output: sample (B, 320, H, W)                            │        │
│  │         → res_sample (B, 320, H, W)                           │        │
│  │  ├─→ Downsample (2×2)                                         │        │
│  │  └─→ Output: sample (B, 320, H/2, W/2)                        │        │
│  └─────────────────────────────────────────────────────────────────┘        │
│           │ 保存残差                                                        │
│           ▼                                                                 │
│  ┌─────────────────────────────────────────────────────────────────┐        │
│  │  Down Block 1 (CrossAttnDownBlock2D)                           │        │
│  │  ─────────────────────────────────────                         │        │
│  │  Input: sample (B, 320, H/2, W/2)                             │        │
│  │  ├─→ ResNet + Self-Attn + Cross-Attn                          │        │
│  │  └─→ Output: sample (B, 640, H/2, W/2)                        │        │
│  │         → res_samples                                         │        │
│  │  ├─→ Downsample (2×2)                                         │        │
│  │  └─→ Output: sample (B, 640, H/4, W/4)                        │        │
│  └─────────────────────────────────────────────────────────────────┘        │
│           │ 保存残差                                                        │
│           ▼                                                                 │
│  ┌─────────────────────────────────────────────────────────────────┐        │
│  │  Down Block 2 (CrossAttnDownBlock2D)                           │        │
│  │  ─────────────────────────────────────                         │        │
│  │  Input: sample (B, 640, H/4, W/4)                             │        │
│  │  ├─→ ResNet + Self-Attn + Cross-Attn                          │        │
│  │  └─→ Output: sample (B, 1280, H/4, W/4)                       │        │
│  │         → res_samples                                         │        │
│  │  ├─→ Downsample (2×2)                                         │        │
│  │  └─→ Output: sample (B, 1280, H/8, W/8)                       │        │
│  └─────────────────────────────────────────────────────────────────┘        │
│           │ 保存残差                                                        │
│           ▼                                                                 │
│  ┌─────────────────────────────────────────────────────────────────┐        │
│  │  Down Block 3 (DownBlock2D - 无交叉注意力)                     │        │
│  │  ────────────────────────────────────────                      │        │
│  │  Input: sample (B, 1280, H/8, W/8)                            │        │
│  │  ├─→ ResNet (无 Cross-Attn)                                   │        │
│  │  └─→ Output: sample (B, 1280, H/8, W/8)                       │        │
│  │         → res_samples                                         │        │
│  │  注: 无下采样 (最终分辨率)                                     │        │
│  └─────────────────────────────────────────────────────────────────┘        │
│           │ 保存残差                                                        │
│           ▼                                                                 │
│                down_block_res_samples 收集了所有中间层特征                   │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
           │
           ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│              5. 中间层 (UNet Middle Block - Bottleneck)                      │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  Input: sample (B, 1280, H/8, W/8) + emb (B, 1280)                         │
│                                                                              │
│  UNetMidBlock2DCrossAttn:                                                  │
│  ├─→ ResNet + Self-Attn + Cross-Attn + ResNet                             │
│  └─→ Output: sample (B, 1280, H/8, W/8) [最深层特征]                       │
│                                                                              │
│  [中间层作用]                                                              │
│  • 充分融合高级语义信息                                                    │
│  • 将文本提示完全整合到特征中                                              │
│  • 融合事件类型控制信息                                                    │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
           │
           ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│           6. ControlNet 输出映射 (ControlNet Output Mapping)                │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  [⭐ ControlNet 零初始化关键 ⭐]                                             │
│  所有输出层都使用 zero_module() 初始化                                      │
│  确保训练初期对 UNet 没有影响                                               │
│                                                                              │
│  down_block_res_samples 映射流程:                                           │
│  ┌─────────────────────────────────────────────────────────────┐            │
│  │  for each (down_block_res, controlnet_block)                │            │
│  │  ────────────────────────────────────────                   │            │
│  │  down_block_res ──→ controlnet_block(1×1 Conv, zero_init)   │            │
│  │  ──→ down_block_res_sample                                  │            │
│  │  ──→ controlnet_down_block_res_samples                      │            │
│  └─────────────────────────────────────────────────────────────┘            │
│                                                                              │
│  mid_block_res 映射:                                                        │
│  ┌─────────────────────────────────────────────────────────────┐            │
│  │  sample ──→ controlnet_mid_block(1×1 Conv, zero_init)       │            │
│  │  ──→ mid_block_res_sample                                   │            │
│  └─────────────────────────────────────────────────────────────┘            │
│                                                                              │
│  输出维度汇总:                                                              │
│  • down_block_res_samples: 13 个张量 (各层残差)                             │
│    - 1 × (B, 320, H, W)                                                     │
│    - 3 × (B, 320, H/2, W/2)                                                 │
│    - 3 × (B, 640, H/4, W/4)                                                 │
│    - 3 × (B, 1280, H/8, W/8)                                                │
│    - 2 × (B, 1280, H/8, W/8)                                                │
│  • mid_block_res_sample: (B, 1280, H/8, W/8)                                │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
           │
           ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│             7. 条件强度缩放 (Conditioning Scale Adjustment)                 │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  IF guess_mode=True:                                                        │
│  ────────────────                                                           │
│  scales = logspace(-1, 0, len(down_block_samples)+1)  [0.1 → 1.0]         │
│  down_block_res_samples[i] *= scales[i] * conditioning_scale               │
│  mid_block_res_sample *= scales[-1] * conditioning_scale                   │
│                                                                              │
│  ELSE (normal mode):                                                        │
│  ─────────────────────                                                      │
│  down_block_res_samples[i] *= conditioning_scale  (通常 1.0)               │
│  mid_block_res_sample *= conditioning_scale                                │
│                                                                              │
│  [说明]                                                                    │
│  • conditioning_scale: 控制 ControlNet 对 UNet 的影响强度                   │
│  • guess_mode: 逐层递减缩放，从浅层 0.1 到深层 1.0                          │
│  • 最终输出 ControlNetOutput(                                               │
│      down_block_res_samples,  # 13 × scaled residuals                      │
│      mid_block_res_sample      # 1 × scaled residual                       │
│    )                                                                        │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
           │
           ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│      8. UNet 解码器 (在 NeDSPipeline 中进行 - 配合 ControlNet 输出)         │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  UNet 前向传播:                                                            │
│  ├─→ 输入: latent (B, 4, H/8, W/8) [当前噪声]                              │
│  ├─→ 输入: emb (B, 1280)  [时间 + 文本 + 事件嵌入]                           │
│  ├─→ 输入: controlnet_outputs (ControlNet 的输出)                          │
│  │         • down_block_additional_residuals (13 个)                       │
│  │         • mid_block_additional_residual (1 个)                          │
│  │                                                                          │
│  ├─→ DownBlocks + MidBlock (添加 ControlNet 残差)                          │
│  ├─→ UpBlocks (使用跳接连接)                                               │
│  └─→ 输出: noise_pred (B, 4, H/8, W/8)                                    │
│                                                                              │
│  [UNet 与 ControlNet 的交互]                                               │
│  • ControlNet 生成空间条件                                                │
│  • UNet 使用这些条件引导噪声预测                                           │
│  • 最终得到受控的去噪过程                                                 │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
           │
           ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│         9. 噪声预测与无分类器引导 (Noise Prediction & Classifier-Free CFG) │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  生成两个预测:                                                             │
│  ┌─────────────────────────────────────────────────────────┐                │
│  │ 预测 1: 带条件 (with text prompt)                       │                │
│  │  noise_pred_text = UNet(sample, t, text_emb)           │                │
│  └─────────────────────────────────────────────────────────┘                │
│                                                                              │
│  ┌─────────────────────────────────────────────────────────┐                │
│  │ 预测 2: 无条件 (unconditional)                         │                │
│  │  noise_pred_uncond = UNet(sample, t, empty_emb)        │                │
│  └─────────────────────────────────────────────────────────┘                │
│                                                                              │
│  无分类器引导合并:                                                         │
│  ┌─────────────────────────────────────────────────────────┐                │
│  │ noise_pred = noise_pred_uncond +                        │                │
│  │              guidance_scale * (noise_pred_text - noise_pred_uncond)     │
│  │                                                                          │
│  │ IF guidance_scale = 7.5 (default):                     │                │
│  │   noise_pred = 1.0 × noise_pred_uncond +              │                │
│  │                7.5 × (noise_pred_text - noise_pred_uncond)             │
│  │             = noise_pred_uncond + 7.5 * diff          │                │
│  └─────────────────────────────────────────────────────────┘                │
│                                                                              │
│  [CFG 作用]                                                               │
│  • 增强文本提示对生成的影响                                                │
│  • guidance_scale 越大，越接近文本描述                                     │
│  • 同时保持 ControlNet 条件约束                                            │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
           │
           ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│        10. 去噪调度步骤 (Scheduler Step - 逐步去噪)                         │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  input: latents (B, 4, H/8, W/8)  [当前噪声]                               │
│         noise_pred                 [预测噪声]                               │
│         t                          [时间步]                                │
│                                                                              │
│  scheduler.step(noise_pred, t, latents, ...)                              │
│                                                                              │
│  输出: latents (B, 4, H/8, W/8)  [下一时间步的潜变量]                       │
│        ✓ 更少噪声                                                          │
│        ✓ 更接近真实变化图像                                               │
│                                                                              │
│  [去噪流程示意]                                                            │
│  t=999 → t=500 → t=0 迭代过程                                             │
│  高噪声        中等噪声      清晰变化图像                                    │
│  ┌───────────────────────────────────────────────┐                         │
│  │     DDPM/DDIM 调度器的数学原理                │                         │
│  │     x_t-1 = sqrt(α_{t-1}) × x̂_0 +            │                         │
│  │             sqrt(1 - α_{t-1}) × ε            │                         │
│  │     其中 x̂_0 从 noise_pred 估计              │                         │
│  └───────────────────────────────────────────────┘                         │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
           │
           ▼
┌─────────────────────────────────────────────────────────────────────────────┐
│                  11. VAE 解码 (VAE Decoding)                                │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  Input:  latents (B, 4, H/8, W/8)  [最终潜变量]                            │
│                                                                              │
│  VAE Decoder:                                                              │
│  latents → scale by vae.config.scaling_factor                             │
│          → VAE decoder (逆向过程)                                          │
│          → image (B, 3, H, W)  [像素空间]                                 │
│                                                                              │
│  后处理:                                                                   │
│  image = image / 2 + 0.5                                                   │
│  image = image.clamp(0, 1)                                                 │
│  image = image * 255                                                       │
│  image = image.astype(uint8)                                               │
│                                                                              │
│  输出: PIL.Image 或 numpy array                                            │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

---

## 二、向量维度变化详细追踪

### 2.1 完整数据流维度变化表

| 阶段 | 张量名称 | 输入维度 | 操作 | 输出维度 | 说明 |
|------|---------|---------|------|---------|------|
| **初始输入** | sample | (B, 4, H, W) | - | - | 噪声潜变量 (从正态分布采样) |
| | pre_latents | (B, 4, H, W) | - | - | 前帧图像的潜变量表示 |
| | controlnet_cond | (B, 6, H, W) | - | - | 5通道掩码 + 1通道其他 |
| | timestep | int/scalar | - | - | 时间步 (0~999) |
| | event_label | (B,) | - | - | 事件类型 [0-6] |
| **时间嵌入** | t_emb | int → (B,) | time_proj | (B, 320) | 正弦位置编码 |
| | emb | (B, 320) | time_embedding | (B, 1280) | 时间嵌入 |
| | event_emb | (B,) | event_embedding | (B, 1280) | 事件类型嵌入 |
| | emb (final) | (B, 1280) | + event_emb | (B, 1280) | 融合的时间-事件嵌入 |
| **特征融合** | sample | (B, 4, H, W) | conv_in | (B, 320, H, W) | 噪声编码 |
| | pre_latents | (B, 4, H, W) | conv_latent | (B, 320, H, W) | 前帧特征 |
| | pmask | (B, 5, H, W) | pmask_embedding | (B, 320, H, W) | 掩码特征编码 |
| | concat | [(B,320), (B,320)] | cat(dim=1) | (B, 640, H, W) | 特征拼接 |
| | fused | (B, 640, H, W) | conv_cond_out | (B, 320, H, W) | 融合后特征 |
| | sample | (B, 320, H, W) | + fused | (B, 320, H, W) | 加法融合 |
| **Down Block 0** | sample | (B, 320, H, W) | resnet+attn | (B, 320, H, W) | 特征保留 |
| | | (B, 320, H, W) | downsample | (B, 320, H/2, W/2) | 2×下采样 |
| **Down Block 1** | sample | (B, 320, H/2, W/2) | resnet+attn+conv | (B, 640, H/2, W/2) | 通道增加 |
| | | (B, 640, H/2, W/2) | downsample | (B, 640, H/4, W/4) | 2×下采样 |
| **Down Block 2** | sample | (B, 640, H/4, W/4) | resnet+attn+conv | (B, 1280, H/4, W/4) | 通道增加 |
| | | (B, 1280, H/4, W/4) | downsample | (B, 1280, H/8, W/8) | 2×下采样 |
| **Down Block 3** | sample | (B, 1280, H/8, W/8) | resnet | (B, 1280, H/8, W/8) | 无下采样 |
| **Mid Block** | sample | (B, 1280, H/8, W/8) | resnet+attn | (B, 1280, H/8, W/8) | 最深层 |
| **ControlNet输出** | down_samples[i] | 各层残差 | controlnet_block | 各层维度×cond_scale | 零初始化输出 |
| | mid_sample | (B, 1280, H/8, W/8) | controlnet_mid_block | (B, 1280, H/8, W/8) | ControlNet中间块输出 |
| **无分类器引导** | noise_uncond | (B, 4, H/8, W/8) | UNet (empty_emb) | (B, 4, H/8, W/8) | 无条件预测 |
| | noise_text | (B, 4, H/8, W/8) | UNet (text_emb) | (B, 4, H/8, W/8) | 有条件预测 |
| | noise_pred | blend | guidance_scale × mix | (B, 4, H/8, W/8) | 合并后预测 |
| **去噪步骤** | latents | (B, 4, H/8, W/8) | scheduler.step | (B, 4, H/8, W/8) | 去噪一步 |
| **VAE解码** | latents | (B, 4, H/8, W/8) | VAE decode | (B, 3, H, W) | 最终图像 |

### 2.2 关键维度计算说明

```
假设输入分辨率: H=512, W=512, Batch=1

层级0: (1, 320, 512, 512)  - 初始编码后
       │
       ├─ down_block_0: ResNet → (1, 320, 512, 512)
       │                 downsample → (1, 320, 256, 256)
       │
层级1: (1, 320, 256, 256)
       │
       ├─ down_block_1: ResNet+conv → (1, 640, 256, 256)
       │                 downsample → (1, 640, 128, 128)
       │
层级2: (1, 640, 128, 128)
       │
       ├─ down_block_2: ResNet+conv → (1, 1280, 128, 128)
       │                 downsample → (1, 1280, 64, 64)
       │
层级3: (1, 1280, 64, 64)  [最深层 = H/8, W/8]
       │
       └─ down_block_3: ResNet → (1, 1280, 64, 64)
          
mid_block: (1, 1280, 64, 64) → (1, 1280, 64, 64)

ControlNet 输出:
  down_block_res_samples: [
    (1, 320, 512, 512),    # 层0
    (1, 320, 512, 512),    # 层0 res
    (1, 320, 256, 256),    # 层0 下采样
    (1, 640, 256, 256),    # 层1
    ... (共13个)
    (1, 1280, 64, 64)      # 层3
  ]
  
  mid_block_res_sample: (1, 1280, 64, 64)
```

---

## 三、特征融合核心机制

### 3.1 三层融合架构

```
┌─────────────────────────────────────────────────────────────┐
│                    融合层级 1: 特征提取                      │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  ┌─ 噪声特征 ─────┐   ┌─ 前帧特征 ────┐   ┌─ 掩码特征 ──┐  │
│  │ conv_in        │   │ conv_latent   │   │pmask_emb   │  │
│  │ 4→320         │   │ 4→320        │   │ 5→320     │  │
│  └────────────────┘   └───────────────┘   └────────────┘  │
│                                                              │
└─────────────────────────────────────────────────────────────┘
          │                      │                      │
          │                      ▼                      │
          │           ┌────────────────────┐            │
          └───────────►│ 掩码编码                        │
                       │ (多层卷积)         │            │
                       │ 16→32→96→128→320 │            │
                       └────────────────────┘            │
                                 │                       │
          ┌──────────────────────┤                       │
          │                      ▼                       │
          │           ┌────────────────────┐             │
          │           │ 前帧特征保留                     │
          │           │ (直接使用潜变量)  │             │
          │           └────────────────────┘             │
          │                      │                       │
          └──────────────────────┴───────────────────────┘
                       │
                       ▼
┌─────────────────────────────────────────────────────────────┐
│              融合层级 2: 特征拼接与降维                      │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│         前帧特征 (B, 320, H, W)                             │
│              +                                              │
│         掩码特征 (B, 320, H, W)                             │
│              │                                              │
│              ▼                                              │
│         拼接 (B, 640, H, W)                                │
│              │                                              │
│              ▼                                              │
│         Conv2d (640→320, 1×1)  [特征降维]                │
│              │                                              │
│              ▼                                              │
│         (B, 320, H, W)                                      │
│                                                              │
└─────────────────────────────────────────────────────────────┘
          │
          ▼
┌─────────────────────────────────────────────────────────────┐
│              融合层级 3: 空间精化与相加                      │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  SiLU激活 + 3×3卷积 [第1层]                                │
│       ▼                                                     │
│  SiLU激活 + 3×3卷积 [第2层]  ← 捕捉空间相关性            │
│       ▼                                                     │
│  融合特征 (B, 320, H, W)                                   │
│       │                                                     │
│       + 噪声特征 (B, 320, H, W)                            │
│       │                                                     │
│       ▼                                                     │
│  最终融合样本 (B, 320, H, W)                               │
│  ✓ 包含噪声信息                                            │
│  ✓ 包含前帧特征                                            │
│  ✓ 包含变化掩码信息                                        │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

### 3.2 事件标签融合机制

```
事件类别 (0-6):
0 = 无变化
1 = 建筑出现
2 = 建筑消失
3 = 建筑扩展
4 = 建筑缩小
5 = 建筑变形
6 = 其他变化

融合流程:
┌─────────────────────────────┐
│  event_label: (B,)          │  例如: [0, 2, 5, 1, ...]
│  值域: 0-6 (7个类别)       │
└──────────────┬──────────────┘
               │
               ▼
┌─────────────────────────────┐
│  event_embedding            │
│  Embedding(7, 1280)         │  7种事件 → 1280维向量
└──────────────┬──────────────┘
               │
               ▼
┌─────────────────────────────┐
│  event_emb: (B, 1280)       │  每个样本得到对应事件的嵌入
│  例如: [[...320维...],      │
│         [...320维...],      │
│         [...320维...]]      │
└──────────────┬──────────────┘
               │
               ▼
┌─────────────────────────────┐
│  emb = emb + event_emb      │  时间嵌入 + 事件嵌入
│  维度: (B, 1280)            │
│                              │
│  最终融合的时间-事件向量:   │
│  ✓ 时间信息 (噪声程度)     │
│  ✓ 事件类型信息            │
│  ✓ 空间变化指导            │
└─────────────────────────────┘
```

---

## 四、扩散过程详解

### 4.1 去噪迭代过程

```
                          扩散模型的去噪循环
                          
┌─────────────────────────────────────────────────────────────────┐
│ 初始状态: 纯高斯噪声 x_T ~ N(0, I)                             │
│ 目标状态: 清晰变化图像 x_0                                      │
└─────────────────────────────────────────────────────────────────┘

t = 999 (噪声最多)
  ↓
  x_999 = 完全噪声 (B, 4, H/8, W/8)
  │
  ├─ UNet 前向: 预测 noise_999
  ├─ ControlNet 前向: 提供空间条件
  ├─ 应用无分类器引导
  ├─ Scheduler: 去噪一步
  └─→ x_998

t = 998
  ↓
  x_998 = 98% 噪声 + 2% 信息
  │
  ├─ UNet 前向: 预测 noise_998
  ├─ ControlNet 提供条件
  ├─ 应用无分类器引导
  ├─ Scheduler: 去噪一步
  └─→ x_997

...

t = 500 (中间点)
  ↓
  x_500 = 50% 噪声 + 50% 信息
  │
  ├─ UNet 前向: 预测 noise_500
  ├─ ControlNet 提供条件 [变化约束增强]
  ├─ 应用无分类器引导
  ├─ Scheduler: 去噪一步
  └─→ x_499

...

t = 1 (噪声最少)
  ↓
  x_1 = 99% 信息 + 1% 噪声
  │
  ├─ UNet 前向: 预测 noise_1
  ├─ ControlNet 提供条件
  ├─ 应用无分类器引导
  ├─ Scheduler: 去噪一步
  └─→ x_0

t = 0 (完成!)
  ↓
  x_0 = 潜空间清晰图像 (B, 4, H/8, W/8)
  │
  └─→ VAE 解码 → RGB 图像 (B, 3, H, W)


[关键: ControlNet 的作用]

在整个去噪过程中:

第一阶段 (t=999~700): ControlNet 贡献 20%
  • 建立大尺度变化结构
  • 定位变化区域

第二阶段 (t=699~300): ControlNet 贡献 50%
  • 细化变化细节
  • 融合前后帧信息

第三阶段 (t=299~0): ControlNet 贡献 30%
  • 精细纹理调整
  • 保持变化约束
```

### 4.2 单步去噪数学原理

```
DDIM 调度器的单步去噪:

Input:
  x_t: 当前噪声潜变量 (B, 4, H/8, W/8)
  ε_t: UNet 预测的噪声 (B, 4, H/8, W/8)
  t: 当前时间步 (int)
  
Step 1: 计算噪声系数
  α_t = sqrt(1 - β_t)                    # β_t 是累积信噪比
  
Step 2: 预测去噪样本
  x_0_pred = (x_t - sqrt(1 - ᾱ_t) * ε_t) / sqrt(ᾱ_t)
  
Step 3: 重新加噪 (较小噪声)
  σ_t = sqrt((1 - ᾱ_{t-1}) / (1 - ᾱ_t)) * sqrt(1 - ᾱ_t / ᾱ_{t-1})
  
  x_{t-1} = sqrt(ᾱ_{t-1}) * x_0_pred + 
            sqrt(1 - ᾱ_{t-1}) * ε_t +
            σ_t * z  (z ~ N(0, I))

Output:
  x_{t-1}: 下一步的潜变量 (噪声减少)
```

---

## 五、NeDS 创新点总结

### 5.1 相比标准 ControlNet 的改进

| 特性 | 标准 ControlNet | NeDS | 优势 |
|------|----------------|------|------|
| **条件输入** | 单一条件图 | 前帧+掩码+事件 | 多源约束更强 |
| **前帧处理** | ✗ 无 | 通过 conv_latent | 利用时间一致性 |
| **事件感知** | ✗ 无 | event_embedding | 控制变化类型 |
| **掩码编码** | 标准卷积 | pmask_embedding | 5通道→1280维 |
| **特征融合** | 简单拼接 | 多层卷积融合 | 更好的特征整合 |
| **应用场景** | 通用条件生成 | 遥感变化检测 | 专业化设计 |

### 5.2 向量融合的优雅设计

```
三个独立特征流:
┌───────────────┐  ┌───────────────┐  ┌───────────────┐
│ 噪声 + 编码   │  │ 前帧 + 编码   │  │ 掩码 + 编码   │
│ 320维         │  │ 320维         │  │ 320维         │
└────────┬──────┘  └────────┬──────┘  └────────┬──────┘
         │                  │                  │
         └──────────────────┼──────────────────┘
                            │
                            ▼ 拼接
                     640维向量
                            │
                    ▼ 融合网络
                     320维向量 (精化)
                            │
         ┌──────────────────┴──────────────────┐
         │                                     │
         │ 保留原始噪声特征        融合特征相加
         │ 320维                  (最终 320维)
         │
    ✓ 保留原始信息
    ✓ 融合相关信息
    ✓ 维度高效
    ✓ 梯度流通顺畅
```

---

## 六、完整推理示例代码

```python
# 完整的 NeDS 推理流程示意

import torch
from torchange.models.neds import NeDSPipeline, NeDS
from diffusers import AutoencoderKL, DDIMScheduler
from transformers import CLIPTextModel, CLIPTokenizer

# 初始化组件
device = "cuda"
vae = AutoencoderKL.from_pretrained("...").to(device)
tokenizer = CLIPTokenizer.from_pretrained("...")
text_encoder = CLIPTextModel.from_pretrained("...").to(device)
unet = UNet2DConditionModel.from_pretrained("...").to(device)
controlnet = NeDS.from_pretrained("...").to(device)
scheduler = DDIMScheduler.from_pretrained("...")

# 初始化 Pipeline
pipeline = NeDSPipeline(
    vae=vae,
    text_encoder=text_encoder,
    tokenizer=tokenizer,
    unet=unet,
    controlnet=controlnet,
    scheduler=scheduler
)

# 准备输入
pre_image = torch.randn(1, 3, 512, 512)  # 前帧图像
post_mask = torch.randn(1, 5, 512, 512)  # 变化掩码
event_label = torch.tensor([2])            # 事件类别
prompt = "建筑物消失"

# 推理
output = pipeline(
    pre_image=pre_image,
    post_mask=post_mask,
    event_label=event_label,
    prompt=prompt,
    num_inference_steps=50,
    guidance_scale=7.5,
    controlnet_conditioning_scale=1.0
)

# 获取结果
generated_image = output.images[0]
```

---

## 七、关键参数说明

### 7.1 推理参数

| 参数 | 默认值 | 范围 | 说明 |
|------|--------|------|------|
| `num_inference_steps` | 50 | 20-100 | 去噪步数越多质量越好但速度越慢 |
| `guidance_scale` | 7.5 | 1-15 | 文本引导强度，越高越接近描述 |
| `controlnet_conditioning_scale` | 1.0 | 0-2 | ControlNet 影响强度 |
| `eta` | 0.0 | 0-1 | DDIM 随机性参数 |
| `num_images_per_prompt` | 1 | - | 每个提示生成多少图像 |
| `guess_mode` | False | - | 是否使用逐层递减缩放 |

### 7.2 模型配置

```python
# 默认配置 (基于 SD v1.5)
{
    "in_channels": 4,
    "conditioning_channels": 3,
    "block_out_channels": (320, 640, 1280, 1280),
    "layers_per_block": 2,
    "cross_attention_dim": 768,  # CLIP-Large
    "time_embed_dim": 1280,       # block_out_channels[0] * 4
    "num_class_embeds": 0,
    "num_event_embeds": 7,        # NeDS 特有
}
```

---

## 八、性能分析

### 8.1 计算复杂度

```
输入: (B=1, H=512, W=512)
潜空间: (1, 4, 64, 64)

ControlNet 计算量:
├─ 特征融合: ~10M FLOPs
├─ 下采样编码: ~800M FLOPs
├─ 中间块: ~100M FLOPs
└─ 总计: ~910M FLOPs

UNet 计算量:
├─ 下采样: ~2B FLOPs
├─ 中间块: ~500M FLOPs
├─ 上采样: ~2B FLOPs
└─ 总计: ~4.5B FLOPs

单步推理: ~5.4B FLOPs
50步推理: ~270B FLOPs

时间: 50 steps × 50ms/step ≈ 2.5秒 (GPU)
```

### 8.2 内存占用

```
Model Parameters:
├─ UNet: ~860M
├─ ControlNet: ~370M
├─ Text Encoder: ~123M
├─ VAE: ~84M
└─ 总计: ~1.4B 参数

推理时显存 (FP32):
├─ 模型权重: ~5.6GB
├─ 激活值: ~2GB
├─ 临时缓存: ~1GB
└─ 总计: ~8.6GB

使用 FP16 可降低至 ~4.3GB
```

---

## 九、完整数据流程图 (ASCII)

```
输入数据
├─ pre_image (B,3,512,512) ──→ VAE编码 ──→ pre_latents (B,4,64,64)
├─ post_mask (B,5,512,512)
├─ event_label (B,)
├─ prompt (str)
└─ timestep t

         ▼
    文本编码
    prompt ──→ tokenizer ──→ token_ids
              ──→ text_encoder ──→ encoder_hidden_states (B,77,768)

         ▼
    噪声采样
    x_t ~ N(0,I) ──→ (B,4,64,64)

         ▼
    NeDS ControlNet 前向
    ├─ 输入: sample, timestep, encoder_hidden_states
    │        pre_latents, event_labels, controlnet_cond
    │
    ├─ 时间-事件嵌入融合
    ├─ 特征融合 (前帧+掩码)
    ├─ UNet下采样编码器
    ├─ UNet中间块
    └─ 输出: down_block_res_samples, mid_block_res_sample

         ▼
    UNet 前向
    ├─ 输入: x_t, emb, encoder_hidden_states
    │        down_block_additional_residuals (ControlNet)
    │        mid_block_additional_residual (ControlNet)
    │
    ├─ 下采样 + 中间块
    ├─ 上采样 + 残差连接
    └─ 输出: noise_pred_text

         ▼
    无分类器引导
    ├─ UNet 前向 (empty_embed) → noise_pred_uncond
    ├─ 计算: noise_pred = noise_pred_uncond +
    │                     guidance_scale × (noise_pred_text - noise_pred_uncond)
    └─ 输出: noise_pred (引导后)

         ▼
    调度器步进
    ├─ 输入: x_t, noise_pred, t
    ├─ 计算: x_{t-1} = ...去噪公式...
    └─ 输出: x_{t-1}

         ▼ 重复 50 次去噪
    x_0 (最终潜变量)

         ▼
    VAE解码
    x_0 (B,4,64,64) ──→ vae.decode ──→ (B,3,512,512) ──→ PIL.Image
```

---

## 十、总结

NeDS 通过以下创新设计实现了高质量的变化图像生成：

1. **多条件融合**: 前帧 + 掩码 + 事件标签的三层融合
2. **事件感知**: 使用 Embedding 将事件类型融入时间嵌入
3. **时间一致性**: 利用前帧潜变量保持图像连贯性
4. **渐进式去噪**: 50 步迭代逐步去噪，由粗到细
5. **无分类器引导**: 增强文本提示的影响力

关键的向量变化路径：
```
(B,4,512,512) → VAE编码 → (B,4,64,64) → 特征融合 → (B,320,64,64)
  → UNet编码 → ControlNet输出 → UNet解码 → (B,4,64,64)
  → VAE解码 → (B,3,512,512) [最终图像]
```

